{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "intro",
            "metadata": {},
            "source": [
                "# Day 1: The Value Class\n",
                "\n",
                "Building the foundation of our autograd engine - a `Value` class that can track computations and build a computation graph."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "imports",
            "metadata": {},
            "outputs": [],
            "source": [
                "import math\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from graphviz import Digraph"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "value-class-intro",
            "metadata": {},
            "source": [
                "## The Value Class\n",
                "\n",
                "This class wraps a scalar value and tracks:\n",
                "- `data`: the actual value\n",
                "- `grad`: the gradient (derivative of the final output with respect to this value)\n",
                "- `_prev`: the set of Value objects that produced this one\n",
                "- `_op`: the operation that created this Value"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "value-class",
            "metadata": {},
            "outputs": [],
            "source": [
                "class Value:\n",
                "    def __init__(self, data, _children=(), _op='', label=''):\n",
                "        self.data = data\n",
                "        self.grad = 0.0\n",
                "        self._prev = set(_children)\n",
                "        self._op = _op\n",
                "        self.label = label\n",
                "\n",
                "    def __repr__(self):\n",
                "        return f\"Value(data={self.data}, label={self.label})\"\n",
                "\n",
                "    def __add__(self, other):\n",
                "        out = Value(self.data + other.data, (self, other), '+')\n",
                "        return out\n",
                "\n",
                "    def __mul__(self, other):\n",
                "        out = Value(self.data * other.data, (self, other), '*')\n",
                "        return out\n",
                "\n",
                "    def tanh(self):\n",
                "        x = self.data\n",
                "        t = (math.exp(2*x) - 1) / (math.exp(2*x) + 1)\n",
                "        out = Value(t, (self,), 'tanh')\n",
                "        return out"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "viz-intro",
            "metadata": {},
            "source": [
                "## Visualizing the Computation Graph\n",
                "\n",
                "We use Graphviz to visualize the computation graph. Each node shows the label, data value, and gradient."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "draw-dot",
            "metadata": {},
            "outputs": [],
            "source": [
                "def trace(root):\n",
                "    \"\"\"Builds a set of all nodes and edges in the graph.\"\"\"\n",
                "    nodes, edges = set(), set()\n",
                "    def build(v):\n",
                "        if v not in nodes:\n",
                "            nodes.add(v)\n",
                "            for child in v._prev:\n",
                "                edges.add((child, v))\n",
                "                build(child)\n",
                "    build(root)\n",
                "    return nodes, edges\n",
                "\n",
                "def draw_dot(root):\n",
                "    \"\"\"Draws the computation graph using Graphviz.\"\"\"\n",
                "    dot = Digraph(format='svg', graph_attr={'rankdir': 'LR'})\n",
                "    nodes, edges = trace(root)\n",
                "    for n in nodes:\n",
                "        uid = str(id(n))\n",
                "        dot.node(name=uid, label=\"{ %s | data %.4f | grad %.4f }\" % (n.label, n.data, n.grad), shape='record')\n",
                "        if n._op:\n",
                "            dot.node(name=uid + n._op, label=n._op)\n",
                "            dot.edge(uid + n._op, uid)\n",
                "    for n1, n2 in edges:\n",
                "        dot.edge(str(id(n1)), str(id(n2)) + n2._op)\n",
                "    return dot"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "example-intro",
            "metadata": {},
            "source": [
                "## Example: Building a Simple Expression\n",
                "\n",
                "Let's build the expression: `L = (a * b + c) * f`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "example",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Build the computation graph\n",
                "a = Value(2.0, label='a')\n",
                "b = Value(-3.0, label='b')\n",
                "c = Value(10.0, label='c')\n",
                "e = a * b; e.label = 'e'\n",
                "d = e + c; d.label = 'd'\n",
                "f = Value(-2.0, label='f')\n",
                "L = d * f; L.label = 'L'\n",
                "\n",
                "# Visualize the graph\n",
                "draw_dot(L)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "manual-grad",
            "metadata": {},
            "source": [
                "## Manual Gradient Calculation\n",
                "\n",
                "Let's manually compute the gradients using the chain rule."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "manual-backprop",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Manually set gradients (backpropagation by hand)\n",
                "L.grad = 1.0       # dL/dL = 1\n",
                "f.grad = d.data    # dL/df = d = 4\n",
                "d.grad = f.data    # dL/dd = f = -2\n",
                "c.grad = d.grad    # dL/dc = dL/dd * dd/dc = -2 * 1 = -2\n",
                "e.grad = d.grad    # dL/de = dL/dd * dd/de = -2 * 1 = -2\n",
                "a.grad = e.grad * b.data  # dL/da = dL/de * de/da = -2 * -3 = 6\n",
                "b.grad = e.grad * a.data  # dL/db = dL/de * de/db = -2 * 2 = -4\n",
                "\n",
                "# Visualize with gradients\n",
                "draw_dot(L)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "grad-check-intro",
            "metadata": {},
            "source": [
                "## Gradient Checking with Numerical Differentiation\n",
                "\n",
                "We can verify our gradients using the definition of derivative: `df/dx â‰ˆ (f(x+h) - f(x)) / h`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "grad-check",
            "metadata": {},
            "outputs": [],
            "source": [
                "def grad_check():\n",
                "    h = 0.0001\n",
                "\n",
                "    # Forward pass\n",
                "    a = Value(2.0, label='a')\n",
                "    b = Value(-3.0, label='b')\n",
                "    c = Value(10.0, label='c')\n",
                "    e = a * b; e.label = 'e'\n",
                "    d = e + c; d.label = 'd'\n",
                "    f = Value(-2.0, label='f')\n",
                "    L = d * f; L.label = 'L'\n",
                "    L1 = L.data\n",
                "\n",
                "    # Forward pass with perturbed 'a'\n",
                "    a = Value(2.0 + h, label='a')\n",
                "    b = Value(-3.0, label='b')\n",
                "    c = Value(10.0, label='c')\n",
                "    e = a * b; e.label = 'e'\n",
                "    d = e + c; d.label = 'd'\n",
                "    f = Value(-2.0, label='f')\n",
                "    L = d * f; L.label = 'L'\n",
                "    L2 = L.data\n",
                "\n",
                "    print(f\"Numerical dL/da: {(L2 - L1) / h:.4f}\")\n",
                "    print(f\"Analytical dL/da: 6.0000 (from chain rule)\")\n",
                "\n",
                "grad_check()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "neuron-intro",
            "metadata": {},
            "source": [
                "## A Simple Neuron\n",
                "\n",
                "Let's implement a single neuron with tanh activation: `o = tanh(x1*w1 + x2*w2 + b)`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "neuron",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Inputs\n",
                "x1 = Value(2.0, label='x1')\n",
                "x2 = Value(0.0, label='x2')\n",
                "\n",
                "# Weights\n",
                "w1 = Value(-3.0, label='w1')\n",
                "w2 = Value(1.0, label='w2')\n",
                "\n",
                "# Bias\n",
                "b = Value(6.8813735870195432, label='b')\n",
                "\n",
                "# x1*w1 + x2*w2 + b\n",
                "x1w1 = x1 * w1; x1w1.label = 'x1*w1'\n",
                "x2w2 = x2 * w2; x2w2.label = 'x2*w2'\n",
                "x1w1x2w2 = x1w1 + x2w2; x1w1x2w2.label = 'x1w1+x2w2'\n",
                "n = x1w1x2w2 + b; n.label = 'n'\n",
                "o = n.tanh(); o.label = 'o'\n",
                "\n",
                "# Visualize\n",
                "draw_dot(o)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}