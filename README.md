# Micrograd from Scratch

A step-by-step implementation of a tiny autograd engine and neural network library, inspired by Andrej Karpathy's [micrograd](https://github.com/karpathy/micrograd).

## Overview

This project builds an automatic differentiation engine from scratch, demonstrating the core concepts behind modern deep learning frameworks like PyTorch.

## Progress

- **Day 1**: `Value` class with basic operations (`+`, `*`) and computation graph visualization

## Structure

```
├── day_01_value_class.ipynb   # Day 1: Value object and basic operations
└── README.md
```

## Getting Started

```bash
pip install graphviz matplotlib numpy
```

## Requirements

- Python 3.8+
- graphviz
- matplotlib
- numpy
